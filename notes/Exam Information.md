Изисквания за изпита
* .ipynb файл в който описваме работата си
    * на български или английски език
    * може да използваме какъвто искаме език за програмиране
* Използване на метрика (но не е задължително модела да ни е силен, пример: acurracy 20%, все пак за предпочитане е да имаме силен модел)
* EDA (Exploratory Data Analysis) - това няма да влияе на оценката, но ще ни трябва за проекта
* Описване на действията които предприемаме с данните
* Abstract в началото на notebook-а
* Сами си избираме данните
* Бонуси: 
    * качествен код
    * добри наименувания
    * добра подредба на клетките в notebook-а
    * при използване на модела в web app (може да се използва Azure ML, може да се изпълни Python script на него и той да ни направи web service автоматично)
* Краен срок: 15ти април

Идеи за изпита:
* Хазартни залагания
* Blockchain mining
* участие в състазение
    * намираме изображения със и без воден знак или готови datasets с такива изображения
    * максимален размер на training set-a: 500 000
    * трябва да се направи класификатор, който ни дава вероятност дали дадено изображение има воден знак (Object detection)
        * Ще се предполага че 0.5 вероятност е границата между 2та класа
        * **model_name.predict** трябва да връща 0 или 1
        * **model_name.predict_proba** трябва да връща число между 0 и 1 включително
        * ще се използва "квадратична грешка"
        * optional: model който маха водния знак, има готови модели в интернет
        * може преди да направим модела, да не използваме суровите пиксели
            * а да използваме някаква трансформация на данните (пример: Fourier transform)
            * да използваме филтри (пример: филтър за търсене на ъгли)
        * в https://arxiv.org/ има интересни примери на тази тема, свързани с adversarial training
        * adversarial training - трениране на модели да разпознават "нормални" изображения от "лоши" изображения (хакерски, примера с тостера)

Още бележки
* Трябва да използваме train_test_split, освен ако не правим unsupervised learning
* може да използваме cloud да тренираме машини (ако ще ги тренираме много време)
* трябва да имаме сравнение на поне 2 модела
* може да пробваме dummy classificator и после да сравним резултатите с друг модел за да сме сигурни че модела който тестваме се справя по-добре от dummy classificator
* базов естиматор
	* класификация - логистична регресия
	* регресия - линейна регресия
* туниговане на хипер параметри
* Cross validation
	* Grid search ще пропусне най-добрите резултати ако имам голяма вариация
	* cross validation който дава acurracy различно всеки път е много лош
	* GridSearchCV може да покаже всички резултати, не само най добрите
		* има променлива която може да покаже всички междинни резултати
* Model Selection
* scaling data
	* важно за дървета и SVM
* polynomial features
* търсене на outliers
	* с one-class SVM
	* с RANSAC Regression
* PSA?
* Пример: правим: линейна регресия, регресията със дърво (например Random Forest Regression) ако даде по-ниски резултати от линейната регресия сме объркали параметрите за RFR т.е. имаме голям bias, слаб модел и трябва да увеличим параметрите