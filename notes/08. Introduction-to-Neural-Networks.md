Neural Networks
* Neural Networks try to mimic the way the human brain works
	* Series of interconnected artificial neurons (perceptrons)
	* Can do classification, regression, unsupervised learning, etc.
* Perceptrons were "invented" in the 1940s
	* Great development in the recent years
* "Deep Learning" - ML algorithms which used neural networks
* Cutting Edge applications
	* Machine translation
	* Speech recognition and generation
	* Image recognition
	* Game Playing
	* [Examples of deep learning applications](https://machinelearningmastery.com/inspirational-applications-deep-learning/)
* Neural Networks: Pros and Cons
	* Pros
		* Can be used to model any datasets
			* Arbitrary dataset complexity
			* One type of algorithm can be used for many applications
			* Много сложен модел (т.е. модел с много параметри) означава че може да апроксимира много функции
			* Една невронна мрежа може да
				* предсказва много резултати
				* служи за feature extraction и feature selection
				* В нормалния случай на ML ние правим feature extraction и feature selection по наш усет, но невронните мрежи са способни да направят тази стъпка предварително и да я направят сами
					* т.е. не просто учат от данни които вече познаваме, а могат да учат и от неструктурирани данни и това е много голямо предимство
	* Cons
		* Do not provide any interpretability
			* The classification boundaries are hard to interpret
			* The model is mostly a "black box"
			* NNs are not probabilistic (we can't get a confidence metric)
			* [The dark secrets at the Heart of AI](https://www.technologyreview.com/s/604087/the-dark-secret-at-the-heart-of-ai/)
				* Solutions: trying to explain decisions, combining with other algorithms, etc
		* Нямаме обяснения за действията на невронните мрежи
		* Една невронна мрежа е една матрица от числа, но ние не можем да знаем какво означават тези числа
		* Пример
			1. Имаме самоуправляваща се кола която използва AI
			2. Колата се блъска
			3. Не можем да разберем защо това е станало
		* Can be slow
			* Other models usually train a lot faster, even if we use special hardware
			* Алгоритъма съдържа голям обект в себе си, който трябва да тренира
			* Имаме много на брой данни (по задължение)
				* С малко на брой данни, невронните мрежи не работят добре
				* За да могат да изтренират всеки параметър вътре в тях им трябват много на брой данни (колкото повече, толкова по-добре)
				* В общия случай ни трябват данни които съдържат повече от 500 000 наблюдения
					* 500 000 наблюдения за алгоритмите които сме разглеждали до момента в курса (SVM, Random Forest и т.н.) са много
						* нормално те постигат максималната си точност до 400 000 наблюдения
		* NNs are not a substitute for understanding the problem deeply
			* Не можете да имате проблем който не разбирате и да го дадете на една невронна мрежа
* Perceptron
	* The main "NN unit"
		* Основна градивна единица на една невронна мрежа
	* Algorithm
		* Assign each input a weight
		* Sum all weighted inputs
		* Pass the sum to an **activation function**
			* Decides whether the neuron will activate binary output (i.e. return 1)
			* Usually sigmoid function or step function
		* As result, the perceptron returns 0 or 1
	* One perceptron is enough to solve any linearly separableproblem
	* Perceptron Learning
		* We have to update the weights
		* Adaline (ADAptive LINear Element) - a perceptron that can learn
		* Adaline Learning - update the weight using formula
* Neural Network Architecture
	* Many layers => the error gradients become too small
		* "Vanishing gradient problem"
			* Small gradient => too slow learning
			* Детайли
				1. Във всеки един слой, имаме да изчисляваме някаква линейна комбинация
				2. Да може да update-нем теглата използваме gradient descent
				3. Gradient descent търси производните на всеки един perceptron
				4. Производните стават все по-малки
				5. Когато стигнем близо до минимума, производната на cost function става все по-малка и близка до минимума
				6. Следователно: Колкото по-дълбока е една невронна мрежа, толкова повече проблеми има
				7. За това стандартната архитектура за много дълбоки невронни мрежи не работи
				8. Нормално работим с 1 или 2 слоя
				9. Също така имаме проблеми със числените методи
					* числата ни са floating point number, примерно 32 или 64 битови
					* числата ни са ограничени и от едно число към следващото може да няма голяма разлика
						* т.е. може 2 различни числа да се представят еднакво в паметта което е голям проблем
	* Special algorithms have been developed to deal with this
		* Тъй като дълбоките невронни мрежи не работят по стандартния начин имаме много специлани алгоритми за тях
			* Един то тези алгоритми е да можем преди невронната мрежа да обработваме данните по други начини
			* Друг алгоритъм е да може да комбинираме обучението с нещо друго, например с генетични алгоритми
				* Генетичния алгоритъм е алгоритъм който еволюира, алгоритъм който пак оптимизира някоя функция, която функция е направена да се максимизира, генетичния алгоритъм се опитва да максимизира тази функция на база на някакви параметри
					* пример:
						1. Имаме начална популация
						2. Най-добрите се размножават и дават поколение, другите умират
						3. След това най-добрите от второто поколени, дават трето поколение и т.н.
				* Може да използваме генетичен алгоритъм да намерим хиперпараметрите на невронната мрежа
		* Всички тези неща се изучават в Deep Learning
			* Deep Learning се занимава основно с тва как да накараме невронните мрежи да работят правилно
		* Pre-train the NN one layer at a time using unsupervised learning
		* Use some form of "back-links" (recurrent NNs)
		* Use a genetic algorithm instead of gradient descent
	* Classification using NNs
		* Two classes: one output (0 or 1)
		* Many classes: use one-hot encoding to represent each class, have as many outputs as there are classes
* Neural Networks Learning
	* The type of NN we look is also called a "feed-forward NN"
		* Data follows only forward, there are no "back-links"
	* Learning Algorithm
		* Forward propagation / backpropagation
			* Forward propagation означава един пример от входните данни (input layer) да мине през цялата невронна мрежа и да даде резултат
			* Backpropagation е връщането от крайният резултат към началото
		* Using the data, propagatethe patterns from input to output
		* Based on the output, calculate the error (using a cost function)
		* Backpropagate the error (using derivatives), update the model
		* Основна идея:
			1. Имаме алгоритъм, който тренираме за пръв път
			2. Даваме му един пример от данните
			3. Алгоритъма дава резултат
			4. Резултатът го сравняваме с "реалния" резултат който би трябвало да върне
			5. Сравняваме до колко е голяма разликата между върнатия резултат и реалния
			6. Искаме да разберем къде е станала грешка
			7. Може да опитаме да върнем процеса на обучение наобратно: от изхода към входовете
				* Защо?
					1. Смятаме градиенти, смятаме производни
					2. Производните на практика представляват как се променя функцията която изпълнява невронната мрежа като се промени входа ѝ
					3. Може да направим следното нещо
						* да върнем изхода към output layer-a
						* от output layer-a да върнем всяка една стрелка наобратно и да видим какви са били грешките всеки път
						* да видим спрямо промяната на функцията (производните) колко сме сбъркали
						* после връщаме назад към другите layer и т.н.
							* при връщането назад получаваме грешките в слоевете
							* грешките са gradient-и
							* правим нещо подобно на gradient descent но по по-специален начин
					4. Така можем да подадем изхода като вход и да видим до колко входа който сме имали първоначално е подобен на подаденият изход
						* Интуиция: превеждаме нещо от английски на български и от български на английски и проверяме дали началото и краят са едни и същи
	* We get the "final" weights after repeating the process for several epochs
	* Maths explanationcan be found [here](http://ml-cheatsheet.readthedocs.io/en/latest/backpropagation.html)
	* Classification: just use one-hot encoder
		* MLP = multi-layer perceptron
	* Regression: no activation function at the output layer
	* Regularization: parameter alpha
		* Increasing = less overfitting
		* [Varying regularization in Multi-layer Perceptron](http://scikit-learn.org/stable/auto_examples/neural_networks/plot_mlp_alpha.html#sphx-glr-auto-examples-neural-networks-plot-mlp-alpha-py)
	* Tips
		* A neural network is very sensitiveto feature scaling
			* [0; 1], [-1; 1] or Z
			* Use a scaler, e.g. **StandartScaler**
		* Use fine-tuning to optmize **alpha**
			* usually in the range 0.1 - 0.0000001
			* ако използваме tensorflow основно е по-бързо (така са имплементирани алгоритмите) ако alpha е степен на 2ката
* Convolutional Neural Networks
	* Невронна мрежа с preprocessing
	* Feed-forward NNs inspired by the visual cortex
		* Very useful for working on images
			* Recognition and classification
		* Example: https://www.clarifai.com/demo
	* Main operations
		* Convolution
		* Non-linearity (ReLU - REctified Linear Unit)
		* Pooling (downsampling, subsampling)
		* Classification (fully-connected layer)
	* Idea: before proceeding to classification, perform image processing using convolution, pooling and ReLU
		* This process produces the input features of a classical NN
	* Convolution: slide a particular matrix (called kernel)
		* Имаме изображение което е матрица от пиксели, имам една малка матричка коят е филтъркойто прилагаме на изображението по определен начин
		* При всяка една конволюция игнорираме крайните пиксели
		* Резултатът винаги намалява с една "рамка" от всякъде
		* This produces a new, smaller matrix representing the convolved feature (called feature map)
			* Many filters => "stacked" matrices (3D feature map)
			* feature map - векторно представяне на изображението след много на брой филтри
	* Rectification (ReLU): y = max(0, x)
		* Performed after each convolution
		* Replaces all negative feature map values with 0
			* Convolution is a linear operation and we want to learn non-linear features; this unit introduces non-linearity
		* It's possible to use other functions
		* Result from the operation: rectified feature map
	* Pooling (downsampling)
		* Намаляване на размерността
		* Reduces the feature map size
		* Types: max, average, sum, etc.
			* The function is applied to a "window" over the image
			* Stide: how many pixel we "skip"
	* The combination of convolution, ReLU and pooling layers should output a 1D number vector
		* Representing high-level features of the input images
		* Used as the input to a "standard" feed-forward NN
			* Called fully-connected layer
		* The NN outputs the final result (e.g. image class)
	* Имат големи проблеми
		* Основен проблем е че ако завъртим изображението вече не работят
			* пример: при обучен класификатор завъртаме изображението и вече не дава добри резултати
		* Capsule networks се стремят да оправят този проблем

Допълнителни бележки
* Ако имаме алгоритъм който може да "направи" XOR, можем да направим всичко със него
	* В теорията на компютърните системи е доказано че ако нещо може да имплементира XOR функция, с комбинации от него може да се направи всяка една функция. Един perceptron не може да постигне това, но една невронна мрежа го може. 2 perceptron-на свързани заедно го могат/
* Невронна мрежа с 1 скрит слой може да апроксимира повечето функции
* Невронна мрежа с 2 скрити слоя може да апроксимира всяка функция
* Повече на брой слоеве означава по-дълбока невронна мрежа
* Броя слоеве и броя елементи във всеки един слой са хиперпараметри които се оптимизират
	* Как се оптимизират?
		* В общия случай не се оптимизират и ние можем да си ги изберем
		* Има формули по които да се изчислят
* Невронните мрежи могат да overfit-ват
* Невронните мрежи са спобосни до някъде да си изберат параметри (т.е. да няма нужда да правим feature selection и feature extraction предварително), но това отнема много време за трениране
* Невронните мрежи са много чувстителни към скалиране (трябва да си скалираме данните предварително)
	* най-доброто скалиране за невронните мрежи е MinMax скалиране
* Примерна архитектурана невронна мрежа: **seq2seq**
* За да получим добра апроксимация от невронната мрежа трябва 1 пример да го "завъртим" много на брой пъти
	* но трябва да се внимава защото ако подадем прекалено много пъти едни и същи данни ще ги научи наизуст (overfitting)
* Може да използваме [ReLU](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)) като активационна функция за невронната мрежа или Leaky ReLU. (Helpful link)[http://cs231n.github.io/neural-networks-1/]
* Ако искаме да ползваме дълбока невронна мрежа (т.е. с много слоеве) sklearn няма да ни свърши работа
	* Не поддържа ускорение от GPU (графичен процесор), критично важно за бързината на обучение
	* Има проблема "Vanishing Gradient Problem"
	* Не поддържа много неща
	* Има библиотеки които биха ни свършили работа като например: tensorflow
* **Adam optimizer**: предпочитания начин за оптимизация на една невронна мрежа, друг начин: SGD (Stochastic Gradient Descent) optimizer
	* най-често срещани
	* работят сравнително бързо, но имат големи проблеми
* Генеративни невронни мрежи
	* 2 невронни мрежи които се състезават една с друга.
	* Едната класифицира, другата подготвя данни с които се опитва да излъже класифициращата.
	* Класификатора има за цел да разбере дали това което получава е реално изображение или генерирано изображение.
	* Генератора като вход получава случай данни (шум) и тези данни ги прекарва през себе си и има задача да подлъже класификатора
	* Външен алгоритъм подава на случаен принцип на класификатора изображение което е реално или генерирано
	* В някакъв момент генератора не се справя добре, генерира някакви глупости, някакъв шум и класификатора който е предварително обучен да разпознава фалшиви изображения, много лесно разбира че изображението е фалшиво
	* Външния алгоритъм тогава се връща към класификатора и му "казва" ти позна (ъпдейтва теглата на класификатора), след това ъпдейтва и генератора така че да му "каже" че е сбъркал
	* И пак повтаряме горните стъпки
	* Външния алгоритъм пази accuracy за генерираните изображения и за реалните изображения
		* ако accuracy за двете стане еднакво, класификатора не може да различи генерирано изображение от реално изображение, тогава генератора е постигнал целта си
* Минималните необоходими данни за една невронна мрежа могат да бъдат много повече от минимално необоходимите за един SVM, примерно
	* Може да постигнем по-добри резултати, но по-бавно, това зависи от много неща
		* мрежата
		* оптимизациите ѝ
		* туниговане на параметри
		* архитектура
* Стандартните алгоритми имат проблей с много на брой observations - давате им повече, те не се учат
	* невронните мрежи нямат този проблем

Допълнителни ресурси:
* http://www.asimovinstitute.org/neural-network-zoo/
* https://en.wikipedia.org/wiki/Generative_adversarial_network
* https://medium.com/ai%C2%B3-theory-practice-business/understanding-hintons-capsule-networks-part-i-intuition-b4b559d1159b