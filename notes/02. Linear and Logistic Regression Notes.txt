предимства на Linear and Logistic Regression
	* много бързо се обучават и много бързо връщат резултати

при всеки алгоритъм се връщат бързо резултати, но понякога обучението е много бавно

Регресия - работи със числа, предсказва променлива която е в някакъв интервал от стойности
	пример: каква ще бъде температурата утре?
Класификация - работи със класове, предсказва един от няколко класа, които са предварително зададени
	пример: на тази картинка куче ли има или котка?
	
Data generating function/process
Идеята е да моделираме данните по такъв начин че:
	* да избегнем "шума"
	* да докараме възможно най-точно оригиналната функция
	
Linear Regression
	* Функцията която предполагаме се нарича "моделираща функция"
	* Шумът определя нещо което е важно за самите данни
	* Предполагаме че шумът (случайна променлива) не зависи от данните
	* Една права е най-добра ако разстоянието от всички точки до правата е най-малко
	* Ако сумираме разстоянията, когато имаме идеална права, сумата ще бъде 0
	* total loss function
	* minimizing the output of the total loss function
		* gradient descent
			* descent означава спускане
			* градиента на една функция е свързан с нейните производни
				* производната определя по какъв начин се изменя дадена функция когато се изменя аргумента ѝ
				* ако имаме повече параметри, отново имаме производна, само че тя вече е вектор, а не едно число и се нарича градиент
				* градиента ни показва на къде функцията расте най-много
					* посоката на вектора показва на къде е най-голямото изкачване
					* дължината на вектора показва колко е далеч най-голямото изкачване
					* ако векторът ни е много дълъг => имаме много стръмно изкачване нагоре
					* ако векторът започва да намалява, изкачването става все по-плавно докато стигне минимума
				* във минимум и максимум производните и градиентите са 0
				* градиентите ни показват максимума, но на нас ни трябва минимума и може да използваме отрицателната стойност на градиента
				* вектора има 2 компонента по a и по b, тези 2 компонента са 2 числа (изчисляват се по формули)
				* започваме от някаква точка, намираме ѝ градиента. Този градиент ни дава нови точки на които се изместваме. Продължаваме така докато не намерим минимума. Т.е. правим стъпки към минимума докато не го намерим.
	* RANSAC (RANdom SAmple Consensus)
	* Polynomial Regression
		* curse of dimensioality


Всеки един метод в sklearn има тези 3 метода:
	* fit - обучава алгоритъма
	* predict - предсказва стойности
	* score - оценява алгоритъма

Machine Learning Steps:
	* предполагаме "моделираща функция"
	* намираме мярка за разстояние
		* ако разстоянието е "грешка" - минимизираме
		* ако разстоянието е "награда" - максимизираме
	* намираме функция която трябва да минимизираме/максимизираме (loss function)
		* gradient descent
			* намираме минимум/максимум и вземаме кординатите
				
Означения
	* алфа - learning rate (външен параметър за модела)
	
plt.plot() - прави линия между отделните точки
np.random.normal() - случайни числа, като повечето са близо до 0

features - колонките които ще ни опишат данните
target - колонката която искаме да предсказваме

Anscombe's quartet

Когато избираме модел имаме много предложения, например предполагаме че:
	* връзката е линейна
	* шумът е случаен
	* шумът е малък спрямо полезните данни
	
Logistic Regression and Linear Regression
	* tip: сравнявай винаги с тях
	* лесни са за използване
	* лесни са за обучение
	* дават добри резултати
	
Logistic Regression
	* използва се за КЛАСИФИКАЦИЯ
	* класификацията винаги дава един от класове с която е тренирана
	* много класове
		* one vs all: several predictors
			* one predictor for each class vs the others
		* overall method: calculated the probability of each class
	
	
Регресията и класификацията решават повечето от проблемите свързани с machine learning
Класификацията е по-често използвана

Подобряване
	* Regularization
	* Fine-tuning